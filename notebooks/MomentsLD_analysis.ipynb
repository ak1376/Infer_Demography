{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "7fd06e41",
            "metadata": {},
            "source": [
                "# MomentsLD Parameter Analysis\n",
                "\n",
                "This notebook provides an analysis of MomentsLD optimization results, comparing ground truth parameters with estimated values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "d5ad2e5d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Libraries imported successfully!\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import pickle\n",
                "import json\n",
                "from pathlib import Path\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Configure matplotlib\n",
                "%matplotlib inline\n",
                "plt.rcParams['figure.figsize'] = (12, 8)\n",
                "plt.rcParams['font.size'] = 11\n",
                "\n",
                "print(\"Libraries imported successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "7b030429",
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'Path' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Configuration\u001b[39;00m\n\u001b[1;32m      2\u001b[0m EXPERIMENT_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottleneck\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Change this to your experiment\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m BASE_PATH \u001b[38;5;241m=\u001b[39m \u001b[43mPath\u001b[49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/akapoor/kernlab/Infer_Demography/experiments/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEXPERIMENT_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m SIMULATIONS_PATH \u001b[38;5;241m=\u001b[39m BASE_PATH \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimulations\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m INFERENCES_PATH \u001b[38;5;241m=\u001b[39m BASE_PATH \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minferences\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
                    ]
                }
            ],
            "source": [
                "# Configuration\n",
                "EXPERIMENT_NAME = 'bottleneck'  # Change this to your experiment\n",
                "BASE_PATH = Path(f'/home/akapoor/kernlab/Infer_Demography/experiments/{EXPERIMENT_NAME}')\n",
                "SIMULATIONS_PATH = BASE_PATH / 'simulations'\n",
                "INFERENCES_PATH = BASE_PATH / 'inferences'\n",
                "\n",
                "print(f\"Experiment: {EXPERIMENT_NAME}\")\n",
                "print(f\"Simulations path: {SIMULATIONS_PATH}\")\n",
                "print(f\"Inferences path: {INFERENCES_PATH}\")\n",
                "print(f\"Paths exist: {SIMULATIONS_PATH.exists()}, {INFERENCES_PATH.exists()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "96ab8dbb",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_ground_truth(simulations_path):\n",
                "    \"\"\"Load ground truth parameters from simulation directories.\"\"\"\n",
                "    gt_data = {}\n",
                "    \n",
                "    for sim_dir in sorted(simulations_path.iterdir()):\n",
                "        if not sim_dir.is_dir():\n",
                "            continue\n",
                "        # Accept directories named as numbers (e.g., '0', '1', ...)\n",
                "        if not sim_dir.name.isdigit():\n",
                "            continue\n",
                "        sim_id = sim_dir.name\n",
                "        param_file = sim_dir / 'sampled_params.pkl'\n",
                "        if param_file.exists():\n",
                "            try:\n",
                "                with open(param_file, 'rb') as f:\n",
                "                    params = pickle.load(f)\n",
                "                gt_data[sim_id] = params\n",
                "            except Exception as e:\n",
                "                print(f\"Error loading {param_file}: {e}\")\n",
                "    \n",
                "    print(f\"Loaded ground truth for {len(gt_data)} simulations\")\n",
                "    return gt_data\n",
                "\n",
                "def load_coverage_data(simulations_path):\n",
                "    \"\"\"Load coverage percentage data from bgs.meta.json files.\"\"\"\n",
                "    coverage_data = {}\n",
                "    \n",
                "    for sim_dir in sorted(simulations_path.iterdir()):\n",
                "        if not sim_dir.is_dir():\n",
                "            continue\n",
                "        if not sim_dir.name.isdigit():\n",
                "            continue\n",
                "        sim_id = sim_dir.name\n",
                "        meta_file = sim_dir / 'bgs.meta.json'\n",
                "        if meta_file.exists():\n",
                "            try:\n",
                "                with open(meta_file, 'r') as f:\n",
                "                    meta = json.load(f)\n",
                "                coverage_data[sim_id] = meta.get('sampled_coverage_percent', None)\n",
                "            except Exception as e:\n",
                "                print(f\"Error loading {meta_file}: {e}\")\n",
                "                coverage_data[sim_id] = None\n",
                "        else:\n",
                "            coverage_data[sim_id] = None\n",
                "    \n",
                "    print(f\"Loaded coverage data for {len(coverage_data)} simulations\")\n",
                "    valid_coverage = sum(1 for v in coverage_data.values() if v is not None)\n",
                "    print(f\"  {valid_coverage} simulations have coverage data\")\n",
                "    return coverage_data\n",
                "\n",
                "def load_momentsld_results(inferences_path):\n",
                "    \"\"\"Load MomentsLD optimization results.\"\"\"\n",
                "    results = {}\n",
                "    \n",
                "    # Iterate over sim_* directories in inferences folder\n",
                "    for sim_dir in sorted(inferences_path.glob('sim_*')):\n",
                "        if not sim_dir.is_dir():\n",
                "            continue\n",
                "            \n",
                "        sim_id = sim_dir.name.split('_')[1]\n",
                "        \n",
                "        # Path to MomentsLD results\n",
                "        momentsld_dir = sim_dir / 'MomentsLD'\n",
                "        result_file = momentsld_dir / 'best_fit.pkl'\n",
                "        \n",
                "        if result_file.exists():\n",
                "            try:\n",
                "                with open(result_file, 'rb') as f:\n",
                "                    data = pickle.load(f)\n",
                "                \n",
                "                results[sim_id] = data\n",
                "            except Exception as e:\n",
                "                print(f\"Error loading {result_file}: {e}\")\n",
                "    \n",
                "    print(f\"Loaded MomentsLD results for {len(results)} simulations\")\n",
                "    return results\n",
                "\n",
                "def extract_parameters(moments_data):\n",
                "    \"\"\"Extract parameters and likelihood from moments results.\"\"\"\n",
                "    params = {}\n",
                "    likelihood = None\n",
                "    \n",
                "    # Handle different result file formats\n",
                "    if isinstance(moments_data, dict):\n",
                "        # Look for parameters\n",
                "        if 'best_params' in moments_data:\n",
                "            if isinstance(moments_data['best_params'], dict):\n",
                "                params = moments_data['best_params']\n",
                "            elif 'param_order' in moments_data:\n",
                "                order = moments_data['param_order']\n",
                "                values = moments_data['best_params']\n",
                "                params = dict(zip(order, values))\n",
                "            else:\n",
                "                # Fallback if param_order is missing but we have a list\n",
                "                # You might need to know the order manually if it's not in the file\n",
                "                pass\n",
                "        \n",
                "        # Look for likelihood\n",
                "        for key in ['best_ll', 'log_likelihood', 'll']:\n",
                "            if key in moments_data:\n",
                "                val = moments_data[key]\n",
                "                likelihood = val[0] if isinstance(val, (list, tuple)) else val\n",
                "                break\n",
                "    \n",
                "    if likelihood is not None:\n",
                "        params['log_likelihood'] = float(likelihood)\n",
                "    \n",
                "    return params\n",
                "\n",
                "print(\"Helper functions defined!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ac30d5f9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the data\n",
                "print(\"Loading ground truth parameters...\")\n",
                "ground_truth = load_ground_truth(SIMULATIONS_PATH)\n",
                "\n",
                "print(\"\\nLoading coverage data...\")\n",
                "coverage_data = load_coverage_data(SIMULATIONS_PATH)\n",
                "\n",
                "print(\"\\nLoading MomentsLD results...\")\n",
                "momentsld_results = load_momentsld_results(INFERENCES_PATH)\n",
                "\n",
                "# Show example data\n",
                "if ground_truth:\n",
                "    first_sim = list(ground_truth.keys())[0]\n",
                "    print(f\"\\nExample ground truth parameters (sim {first_sim}):\")\n",
                "    for key, value in ground_truth[first_sim].items():\n",
                "        print(f\"  {key}: {value}\")\n",
                "\n",
                "if coverage_data:\n",
                "    print(f\"\\nExample coverage data:\")\n",
                "    for i, (sim_id, coverage) in enumerate(list(coverage_data.items())[:5]):\n",
                "        print(f\"  Sim {sim_id}: {coverage}% coverage\" if coverage else f\"  Sim {sim_id}: No coverage data\")\n",
                "\n",
                "if momentsld_results:\n",
                "    first_sim = list(momentsld_results.keys())[0]\n",
                "    example_params = extract_parameters(momentsld_results[first_sim])\n",
                "    print(f\"\\nExample estimated parameters (sim {first_sim}):\")\n",
                "    for key, value in example_params.items():\n",
                "        print(f\"  {key}: {value}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e98d284a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create comparison dataframe\n",
                "comparison_data = []\n",
                "\n",
                "for sim_id in ground_truth.keys():\n",
                "    if sim_id not in momentsld_results:\n",
                "        continue\n",
                "        \n",
                "    gt_params = ground_truth[sim_id]\n",
                "    coverage = coverage_data.get(sim_id, None)\n",
                "    \n",
                "    est_data = momentsld_results[sim_id]\n",
                "    est_params = extract_parameters(est_data)\n",
                "    \n",
                "    # Find common parameters\n",
                "    common_params = set(gt_params.keys()) & set(est_params.keys())\n",
                "    common_params.discard('log_likelihood')\n",
                "    \n",
                "    for param in common_params:\n",
                "        gt_val = gt_params[param]\n",
                "        est_val = est_params[param]\n",
                "        \n",
                "        comparison_data.append({\n",
                "            'simulation': sim_id,\n",
                "            'parameter': param,\n",
                "            'ground_truth': gt_val,\n",
                "            'estimated': est_val,\n",
                "            'absolute_error': est_val - gt_val,\n",
                "            'relative_error': (est_val - gt_val) / gt_val if gt_val != 0 else np.nan,\n",
                "            'coverage_percent': coverage\n",
                "        })\n",
                "    \n",
                "    # Add likelihood separately\n",
                "    if 'log_likelihood' in est_params:\n",
                "        comparison_data.append({\n",
                "            'simulation': sim_id,\n",
                "            'parameter': 'log_likelihood',\n",
                "            'ground_truth': np.nan,\n",
                "            'estimated': est_params['log_likelihood'],\n",
                "            'absolute_error': np.nan,\n",
                "            'relative_error': np.nan,\n",
                "            'coverage_percent': coverage\n",
                "        })\n",
                "\n",
                "df = pd.DataFrame(comparison_data)\n",
                "print(f\"Created comparison dataframe with {len(df)} rows\")\n",
                "if not df.empty:\n",
                "    print(f\"Parameters: {sorted(df['parameter'].unique())}\")\n",
                "    print(f\"Simulations: {len(df['simulation'].unique())}\")\n",
                "\n",
                "    # Check coverage data distribution\n",
                "    coverage_stats = df['coverage_percent'].describe()\n",
                "    print(f\"\\nCoverage percentage statistics:\")\n",
                "    print(coverage_stats)\n",
                "\n",
                "    # Show first few rows\n",
                "    display(df.head(10))\n",
                "else:\n",
                "    print(\"No matching data found between ground truth and MomentsLD results.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8c33cb5d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plotting\n",
                "if not df.empty:\n",
                "    parameters = [p for p in df['parameter'].unique() if p != 'log_likelihood']\n",
                "    print(f\"Plotting {len(parameters)} parameters: {parameters}\")\n",
                "    \n",
                "    # 1. Scatter plots: Ground Truth vs Estimated\n",
                "    n_cols = 3\n",
                "    n_rows = (len(parameters) + n_cols - 1) // n_cols\n",
                "    \n",
                "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 5*n_rows))\n",
                "    axes = axes.flatten()\n",
                "    \n",
                "    for i, param in enumerate(parameters):\n",
                "        ax = axes[i]\n",
                "        subset = df[df['parameter'] == param]\n",
                "        \n",
                "        # Scatter plot\n",
                "        ax.scatter(subset['ground_truth'], subset['estimated'], alpha=0.6)\n",
                "        \n",
                "        # 1:1 line\n",
                "        min_val = min(subset['ground_truth'].min(), subset['estimated'].min())\n",
                "        max_val = max(subset['ground_truth'].max(), subset['estimated'].max())\n",
                "        ax.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\n",
                "        \n",
                "        ax.set_title(f'{param}')\n",
                "        ax.set_xlabel('Ground Truth')\n",
                "        ax.set_ylabel('Estimated')\n",
                "        ax.grid(True, alpha=0.3)\n",
                "        \n",
                "        # Log scale if range is large\n",
                "        if max_val / (min_val + 1e-9) > 100:\n",
                "            ax.set_xscale('log')\n",
                "            ax.set_yscale('log')\n",
                "            \n",
                "    # Hide empty subplots\n",
                "    for i in range(len(parameters), len(axes)):\n",
                "        axes[i].axis('off')\n",
                "        \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    # 2. Relative Error Distributions\n",
                "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 5*n_rows))\n",
                "    axes = axes.flatten()\n",
                "    \n",
                "    for i, param in enumerate(parameters):\n",
                "        ax = axes[i]\n",
                "        subset = df[df['parameter'] == param]\n",
                "        \n",
                "        # Histogram of relative error\n",
                "        errors = subset['relative_error'].dropna()\n",
                "        ax.hist(errors, bins=20, alpha=0.7, edgecolor='black')\n",
                "        \n",
                "        ax.axvline(0, color='r', linestyle='--', alpha=0.8)\n",
                "        \n",
                "        ax.set_title(f'{param} Relative Error')\n",
                "        ax.set_xlabel('Relative Error ((Est - GT) / GT)')\n",
                "        ax.set_ylabel('Count')\n",
                "        ax.grid(True, alpha=0.3)\n",
                "        \n",
                "    # Hide empty subplots\n",
                "    for i in range(len(parameters), len(axes)):\n",
                "        axes[i].axis('off')\n",
                "        \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "snakemake-env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
